{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install rouge-score\n!pip install underthesea\n!pip install transformers[torch] datasets evaluate sentencepiece accelerate nltk","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T06:20:22.326506Z","iopub.execute_input":"2025-07-06T06:20:22.326784Z","iopub.status.idle":"2025-07-06T06:21:48.612968Z","shell.execute_reply.started":"2025-07-06T06:20:22.326760Z","shell.execute_reply":"2025-07-06T06:21:48.612207Z"}},"outputs":[{"name":"stdout","text":"Collecting rouge-score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score) (3.9.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (8.1.8)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (1.5.0)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (2024.11.6)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rouge-score) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rouge-score) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rouge-score) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rouge-score) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rouge-score) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rouge-score) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge-score) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge-score) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rouge-score) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rouge-score) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rouge-score) (2024.2.0)\nBuilding wheels for collected packages: rouge-score\n  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=4b1743e0cc44284f5128164ff35d68628064592016f4031346149b49aa12af95\n  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\nSuccessfully built rouge-score\nInstalling collected packages: rouge-score\nSuccessfully installed rouge-score-0.1.2\nCollecting underthesea\n  Downloading underthesea-6.8.4-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: Click>=6.0 in /usr/local/lib/python3.11/dist-packages (from underthesea) (8.1.8)\nCollecting python-crfsuite>=0.9.6 (from underthesea)\n  Downloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from underthesea) (3.9.1)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from underthesea) (4.67.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from underthesea) (2.32.3)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from underthesea) (1.5.0)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from underthesea) (1.2.2)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from underthesea) (6.0.2)\nCollecting underthesea-core==1.0.4 (from underthesea)\n  Downloading underthesea_core-1.0.4-cp311-cp311-manylinux2010_x86_64.whl.metadata (1.7 kB)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->underthesea) (2024.11.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->underthesea) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->underthesea) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->underthesea) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->underthesea) (2025.4.26)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->underthesea) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->underthesea) (1.15.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->underthesea) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->underthesea) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->underthesea) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->underthesea) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->underthesea) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->underthesea) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->underthesea) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn->underthesea) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn->underthesea) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->scikit-learn->underthesea) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.3->scikit-learn->underthesea) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.3->scikit-learn->underthesea) (2024.2.0)\nDownloading underthesea-6.8.4-py3-none-any.whl (20.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading underthesea_core-1.0.4-cp311-cp311-manylinux2010_x86_64.whl (657 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m657.8/657.8 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: underthesea-core, python-crfsuite, underthesea\nSuccessfully installed python-crfsuite-0.9.11 underthesea-6.8.4 underthesea-core-1.0.4\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\nCollecting evaluate\n  Downloading evaluate-0.4.4-py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\nRequirement already satisfied: transformers[torch] in /usr/local/lib/python3.11/dist-packages (4.51.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (0.31.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (4.67.1)\nRequirement already satisfied: torch>=2.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (2.6.0+cu124)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nCollecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.0)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.18)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers[torch]) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers[torch]) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers[torch]) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers[torch]) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers[torch]) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers[torch]) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers[torch]) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers[torch]) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[torch]) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[torch]) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[torch]) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[torch]) (2025.4.26)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0->transformers[torch])\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0->transformers[torch])\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0->transformers[torch])\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0->transformers[torch])\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0->transformers[torch])\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0->transformers[torch])\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0->transformers[torch])\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0->transformers[torch]) (1.3.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0->transformers[torch]) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers[torch]) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers[torch]) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers[torch]) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers[torch]) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers[torch]) (2024.2.0)\nDownloading evaluate-0.4.4-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0mm00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, evaluate\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed evaluate-0.4.4 fsspec-2025.3.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from datasets import load_dataset, DatasetDict\nfrom underthesea import text_normalize\nfrom rouge_score import rouge_scorer\nimport re\nimport torch\nfrom transformers import AutoTokenizer,AutoModelForSeq2SeqLM,DataCollatorForSeq2Seq,Seq2SeqTrainingArguments,Seq2SeqTrainer\n\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-06T06:26:54.495247Z","iopub.execute_input":"2025-07-06T06:26:54.496387Z","iopub.status.idle":"2025-07-06T06:26:54.500704Z","shell.execute_reply.started":"2025-07-06T06:26:54.496359Z","shell.execute_reply":"2025-07-06T06:26:54.499902Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Load Dataset","metadata":{}},{"cell_type":"code","source":"ds = load_dataset(\"vietgpt/news_summarization_vi\")\nds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T06:27:06.533273Z","iopub.execute_input":"2025-07-06T06:27:06.534095Z","iopub.status.idle":"2025-07-06T06:27:09.292852Z","shell.execute_reply.started":"2025-07-06T06:27:06.534067Z","shell.execute_reply":"2025-07-06T06:27:09.292083Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c8b4d5aab024fa5bbaf4d38df61cfeb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)-00000-of-00001-7f6f00607f418ae2.parquet:   0%|          | 0.00/115M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"692b9f26143749f0a918f78bee20d07f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)-00000-of-00001-5f6b579a81bd695a.parquet:   0%|          | 0.00/1.77M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b7f0faabc7644fc81ddd3e7d3610d42"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/65361 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c142341763484d849725587eef129470"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d7f63f26d2241cdbc156e762a40eb0a"}},"metadata":{}},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['content', 'summary'],\n        num_rows: 65361\n    })\n    test: Dataset({\n        features: ['content', 'summary'],\n        num_rows: 1000\n    })\n})"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"train_val_split = ds['train'].train_test_split(\n    test_size=0.1, \n    seed=42        \n)\n\nfinal_ds = DatasetDict({\n    'train': train_val_split['train'],      \n    'validation': train_val_split['test'],  \n    'test': ds['test']                      \n})\nprint(final_ds)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T04:18:57.942796Z","iopub.execute_input":"2025-07-06T04:18:57.943376Z","iopub.status.idle":"2025-07-06T04:18:57.968999Z","shell.execute_reply.started":"2025-07-06T04:18:57.943353Z","shell.execute_reply":"2025-07-06T04:18:57.968401Z"}},"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['content', 'summary'],\n        num_rows: 58824\n    })\n    validation: Dataset({\n        features: ['content', 'summary'],\n        num_rows: 6537\n    })\n    test: Dataset({\n        features: ['content', 'summary'],\n        num_rows: 1000\n    })\n})\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"final_ds = ds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T06:27:24.875975Z","iopub.execute_input":"2025-07-06T06:27:24.876668Z","iopub.status.idle":"2025-07-06T06:27:24.880434Z","shell.execute_reply.started":"2025-07-06T06:27:24.876635Z","shell.execute_reply":"2025-07-06T06:27:24.879705Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def is_not_empty(example):\n    \"\"\"Kiểm tra xem các cột cần thiết có dữ liệu hợp lệ hay không.\"\"\"\n    content_ok = example['content'] and example['content'].strip()\n    summary_ok = example['summary'] and example['summary'].strip()\n    return content_ok and summary_ok\n\ncleaned_ds = final_ds.filter(\n    is_not_empty,\n    num_proc=2\n)\n\nfor split in final_ds.keys():\n    original_rows = len(final_ds[split])\n    cleaned_rows = len(cleaned_ds[split])\n    removed_rows = original_rows - cleaned_rows\n    print(f\"\\nTrong tập '{split}':\")\n    print(f\"  - Số hàng ban đầu: {original_rows}\")\n    print(f\"  - Số hàng sau khi lọc: {cleaned_rows}\")\n    print(f\"  - Số hàng đã loại bỏ: {removed_rows}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T06:27:29.627097Z","iopub.execute_input":"2025-07-06T06:27:29.627379Z","iopub.status.idle":"2025-07-06T06:27:30.821728Z","shell.execute_reply.started":"2025-07-06T06:27:29.627358Z","shell.execute_reply":"2025-07-06T06:27:30.820790Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter (num_proc=2):   0%|          | 0/65361 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14a93a2025ab4f4185a49291622304ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter (num_proc=2):   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18248a960edf4bd4b909321dd19d85c5"}},"metadata":{}},{"name":"stdout","text":"\nTrong tập 'train':\n  - Số hàng ban đầu: 65361\n  - Số hàng sau khi lọc: 64342\n  - Số hàng đã loại bỏ: 1019\n\nTrong tập 'test':\n  - Số hàng ban đầu: 1000\n  - Số hàng sau khi lọc: 981\n  - Số hàng đã loại bỏ: 19\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"def preprocess_function(batch):\n    \"\"\"Áp dụng clean_text cho cả cột content và summary trong một batch.\"\"\"\n    \n    # batch['content'] là một list các chuỗi content\n    # batch['summary'] là một list các chuỗi summary\n    \n    cleaned_contents = [clean_text(text) for text in batch['content']]\n    cleaned_summaries = [clean_text(text) for text in batch['summary']]\n    \n    # Trả về một dictionary với các cột đã được cập nhật\n    batch['content'] = cleaned_contents\n    batch['summary'] = cleaned_summaries\n    \n    return batch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T06:27:35.774117Z","iopub.execute_input":"2025-07-06T06:27:35.774452Z","iopub.status.idle":"2025-07-06T06:27:35.779765Z","shell.execute_reply.started":"2025-07-06T06:27:35.774404Z","shell.execute_reply":"2025-07-06T06:27:35.778995Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def clean_text(text):\n    text = text_normalize(text)\n    text = re.sub(r\"[^\\w\\s.,:;!?()/()-]\", \"\", text)\n    text = re.sub(r\"([.,:;!?)])(\\S)\", r\"\\1 \\2\", text)\n    text = re.sub(r\"\\s+\", \" \", text).strip()\n    \n    def capitalize_after_punctuation(text):\n        sentences = re.split(r\"([.!?])\", text)\n        result = \"\"\n        for i in range(len(sentences)):\n            if sentences[i] in [\".\", \"!\", \"?\"] and i + 1 < len(sentences):\n                sentences[i + 1] = sentences[i + 1].strip().capitalize()\n            result += sentences[i]\n        return result.strip()\n    \n    return capitalize_after_punctuation(text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T06:27:38.647591Z","iopub.execute_input":"2025-07-06T06:27:38.648062Z","iopub.status.idle":"2025-07-06T06:27:38.653398Z","shell.execute_reply.started":"2025-07-06T06:27:38.648038Z","shell.execute_reply":"2025-07-06T06:27:38.652704Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"cleaned_ds = cleaned_ds.map(\n    preprocess_function, \n    batched=True,\n    num_proc=2\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T06:27:42.158300Z","iopub.execute_input":"2025-07-06T06:27:42.159021Z","iopub.status.idle":"2025-07-06T06:29:53.388648Z","shell.execute_reply.started":"2025-07-06T06:27:42.158995Z","shell.execute_reply":"2025-07-06T06:29:53.387895Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map (num_proc=2):   0%|          | 0/64342 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"789f4016995749c194bc9e369bbaa4ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=2):   0%|          | 0/981 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0273057aa9794848bedcbc2c69a0a806"}},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"# Fine-tuning","metadata":{}},{"cell_type":"code","source":"def compute_metrics(eval_pred, tokenizer):\n    predictions, labels = eval_pred\n    predictions = predictions.argmax(axis=-1) if predictions.ndim == 3 else predictions\n\n    # Kiểm tra nếu có giá trị âm trong predictions\n    for batch in predictions:\n        if any(token < 0 for token in batch.flatten()):\n            print(\"Có giá trị âm trong predictions:\", batch)\n            break\n\n    # Loại bỏ giá trị âm trước khi decode\n    predictions = [[token for token in pred if token >= 0] for pred in predictions]\n    \n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    # Sử dụng rouge_scorer để tính ROUGE\n    scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n    scores = [scorer.score(pred, label) for pred, label in zip(decoded_preds, decoded_labels)]\n\n    # Trung bình các giá trị ROUGE\n    rouge1 = sum(score[\"rouge1\"].fmeasure for score in scores) / len(scores)\n    rouge2 = sum(score[\"rouge2\"].fmeasure for score in scores) / len(scores)\n    rougeL = sum(score[\"rougeL\"].fmeasure for score in scores) / len(scores)\n\n    return {\n        \"rouge1\": rouge1,\n        \"rouge2\": rouge2,\n        \"rougeL\": rougeL,\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T04:22:24.242380Z","iopub.execute_input":"2025-07-06T04:22:24.242822Z","iopub.status.idle":"2025-07-06T04:22:24.249462Z","shell.execute_reply.started":"2025-07-06T04:22:24.242800Z","shell.execute_reply":"2025-07-06T04:22:24.248642Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Load tokenizer và model\nmodel_name = \"VietAI/vit5-base\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T06:30:00.490624Z","iopub.execute_input":"2025-07-06T06:30:00.490944Z","iopub.status.idle":"2025-07-06T06:30:07.186207Z","shell.execute_reply.started":"2025-07-06T06:30:00.490919Z","shell.execute_reply":"2025-07-06T06:30:07.185236Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34e948f23253403cbd252be04a29c127"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/820k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b41355f1792a4e099bc6e05b1ca5ec02"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5bb9c0291d8e48e68a90a77d63cb6c22"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd8e38c83f7244888c7a1559657deb63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/702 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfec05b573794ad09d556d737e425af1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/904M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d73fab499242493f9ba97d2d6f3defe0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/904M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1010a5da8ed4a6c9eb6a92c977bb682"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"# Tokenize dataset\ndef preprocess_function(examples):\n    inputs = [\"summarize: \" + doc for doc in examples[\"content\"]]\n    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n    labels = tokenizer(examples[\"summary\"], max_length=128, truncation=True, padding=\"max_length\")\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T06:30:23.554162Z","iopub.execute_input":"2025-07-06T06:30:23.554776Z","iopub.status.idle":"2025-07-06T06:30:23.558876Z","shell.execute_reply.started":"2025-07-06T06:30:23.554752Z","shell.execute_reply":"2025-07-06T06:30:23.558300Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"tokenized_dataset = cleaned_ds.map(preprocess_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T06:30:52.020813Z","iopub.execute_input":"2025-07-06T06:30:52.021375Z","iopub.status.idle":"2025-07-06T06:32:35.719925Z","shell.execute_reply.started":"2025-07-06T06:30:52.021352Z","shell.execute_reply":"2025-07-06T06:32:35.719279Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/64342 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f94988eaf631407cbcb052fb652055c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/981 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f40120d943ae4071a5683a82fa02d2b5"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, label_pad_token_id=tokenizer.pad_token_id, return_tensors=\"pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T06:35:05.516561Z","iopub.execute_input":"2025-07-06T06:35:05.516902Z","iopub.status.idle":"2025-07-06T06:35:05.521268Z","shell.execute_reply.started":"2025-07-06T06:35:05.516883Z","shell.execute_reply":"2025-07-06T06:35:05.520316Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"print(torch.cuda.device_count()) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T06:33:16.642078Z","iopub.execute_input":"2025-07-06T06:33:16.642664Z","iopub.status.idle":"2025-07-06T06:33:16.646683Z","shell.execute_reply.started":"2025-07-06T06:33:16.642639Z","shell.execute_reply":"2025-07-06T06:33:16.645826Z"}},"outputs":[{"name":"stdout","text":"2\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"save_path = \"/kaggle/working/\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T06:33:18.390374Z","iopub.execute_input":"2025-07-06T06:33:18.390950Z","iopub.status.idle":"2025-07-06T06:33:18.394193Z","shell.execute_reply.started":"2025-07-06T06:33:18.390927Z","shell.execute_reply":"2025-07-06T06:33:18.393447Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Training arguments\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=save_path,\n    learning_rate=5e-5,\n    per_device_train_batch_size=2,\n    per_device_eval_batch_size=2,\n    num_train_epochs=3,\n    eval_strategy='epoch',\n    save_total_limit=3,\n    predict_with_generate=True,\n    fp16=True,\n    logging_first_step=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T04:54:50.739776Z","iopub.execute_input":"2025-07-06T04:54:50.740387Z","iopub.status.idle":"2025-07-06T04:54:50.773943Z","shell.execute_reply.started":"2025-07-06T04:54:50.740366Z","shell.execute_reply":"2025-07-06T04:54:50.773392Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(output_dir = save_path,\n                                      do_train=True,\n                                      do_eval=False,\n                                      num_train_epochs=3,\n                                      learning_rate=5e-5,\n                                      warmup_ratio=0.05,\n                                      weight_decay=0.01,\n                                      per_device_train_batch_size=4,\n                                      per_device_eval_batch_size=4,\n                                      group_by_length=True,\n                                      save_strategy = \"no\",\n                                      # gradient_accumulation_steps=4,\n                                      fp16=True,\n                                      # gradient_checkpointing=True,\n                                      )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T06:43:33.874749Z","iopub.execute_input":"2025-07-06T06:43:33.875289Z","iopub.status.idle":"2025-07-06T06:43:33.908325Z","shell.execute_reply.started":"2025-07-06T06:43:33.875266Z","shell.execute_reply":"2025-07-06T06:43:33.907797Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset['train'],\n    data_collator=data_collator,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T06:43:50.787896Z","iopub.execute_input":"2025-07-06T06:43:50.788377Z","iopub.status.idle":"2025-07-06T06:43:50.800180Z","shell.execute_reply.started":"2025-07-06T06:43:50.788354Z","shell.execute_reply":"2025-07-06T06:43:50.799668Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T06:43:58.998195Z","iopub.execute_input":"2025-07-06T06:43:58.998719Z","iopub.status.idle":"2025-07-06T13:30:06.845527Z","shell.execute_reply.started":"2025-07-06T06:43:58.998698Z","shell.execute_reply":"2025-07-06T13:30:06.844867Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250706_064430-c7fnddlv</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/leductai2201/huggingface/runs/c7fnddlv' target=\"_blank\">/kaggle/working/</a></strong> to <a href='https://wandb.ai/leductai2201/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/leductai2201/huggingface' target=\"_blank\">https://wandb.ai/leductai2201/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/leductai2201/huggingface/runs/c7fnddlv' target=\"_blank\">https://wandb.ai/leductai2201/huggingface/runs/c7fnddlv</a>"},"metadata":{}},{"name":"stderr","text":"Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='24129' max='24129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [24129/24129 6:45:27, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>2.198000</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.916700</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.859600</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.834700</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.809400</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.799600</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.780900</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.767200</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>0.737400</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>0.763000</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>0.737200</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>0.742200</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>0.737800</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>0.730900</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>0.723100</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>0.715400</td>\n    </tr>\n    <tr>\n      <td>8500</td>\n      <td>0.639200</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>0.635300</td>\n    </tr>\n    <tr>\n      <td>9500</td>\n      <td>0.631800</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>0.639200</td>\n    </tr>\n    <tr>\n      <td>10500</td>\n      <td>0.609500</td>\n    </tr>\n    <tr>\n      <td>11000</td>\n      <td>0.635800</td>\n    </tr>\n    <tr>\n      <td>11500</td>\n      <td>0.634800</td>\n    </tr>\n    <tr>\n      <td>12000</td>\n      <td>0.626600</td>\n    </tr>\n    <tr>\n      <td>12500</td>\n      <td>0.622900</td>\n    </tr>\n    <tr>\n      <td>13000</td>\n      <td>0.616100</td>\n    </tr>\n    <tr>\n      <td>13500</td>\n      <td>0.618400</td>\n    </tr>\n    <tr>\n      <td>14000</td>\n      <td>0.614200</td>\n    </tr>\n    <tr>\n      <td>14500</td>\n      <td>0.607300</td>\n    </tr>\n    <tr>\n      <td>15000</td>\n      <td>0.605700</td>\n    </tr>\n    <tr>\n      <td>15500</td>\n      <td>0.615200</td>\n    </tr>\n    <tr>\n      <td>16000</td>\n      <td>0.601500</td>\n    </tr>\n    <tr>\n      <td>16500</td>\n      <td>0.552700</td>\n    </tr>\n    <tr>\n      <td>17000</td>\n      <td>0.523200</td>\n    </tr>\n    <tr>\n      <td>17500</td>\n      <td>0.536300</td>\n    </tr>\n    <tr>\n      <td>18000</td>\n      <td>0.533200</td>\n    </tr>\n    <tr>\n      <td>18500</td>\n      <td>0.536800</td>\n    </tr>\n    <tr>\n      <td>19000</td>\n      <td>0.541300</td>\n    </tr>\n    <tr>\n      <td>19500</td>\n      <td>0.529900</td>\n    </tr>\n    <tr>\n      <td>20000</td>\n      <td>0.519800</td>\n    </tr>\n    <tr>\n      <td>20500</td>\n      <td>0.529400</td>\n    </tr>\n    <tr>\n      <td>21000</td>\n      <td>0.530600</td>\n    </tr>\n    <tr>\n      <td>21500</td>\n      <td>0.528600</td>\n    </tr>\n    <tr>\n      <td>22000</td>\n      <td>0.519200</td>\n    </tr>\n    <tr>\n      <td>22500</td>\n      <td>0.525000</td>\n    </tr>\n    <tr>\n      <td>23000</td>\n      <td>0.522700</td>\n    </tr>\n    <tr>\n      <td>23500</td>\n      <td>0.523900</td>\n    </tr>\n    <tr>\n      <td>24000</td>\n      <td>0.526400</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=24129, training_loss=0.6718259308102899, metrics={'train_runtime': 24336.3425, 'train_samples_per_second': 7.932, 'train_steps_per_second': 0.991, 'total_flos': 1.1754470578323456e+17, 'train_loss': 0.6718259308102899, 'epoch': 3.0})"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"model.save_pretrained(save_path)\ntokenizer.save_pretrained(save_path)\n\nprint(f\"Đã lưu xong ở đây này > {save_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T13:44:51.868690Z","iopub.execute_input":"2025-07-06T13:44:51.869307Z","iopub.status.idle":"2025-07-06T13:44:54.612127Z","shell.execute_reply.started":"2025-07-06T13:44:51.869283Z","shell.execute_reply":"2025-07-06T13:44:54.611475Z"}},"outputs":[{"name":"stdout","text":"Đã lưu xong ở đây này > /kaggle/working/\n","output_type":"stream"}],"execution_count":37},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"model = AutoModelForSeq2SeqLM.from_pretrained(\"/kaggle/working/ViT5-finetune\")\nmodel.to('cuda')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T13:45:57.532232Z","iopub.execute_input":"2025-07-06T13:45:57.532549Z","iopub.status.idle":"2025-07-06T13:45:58.055456Z","shell.execute_reply.started":"2025-07-06T13:45:57.532527Z","shell.execute_reply":"2025-07-06T13:45:58.054864Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"T5ForConditionalGeneration(\n  (shared): Embedding(36096, 768)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(36096, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(36096, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=768, out_features=36096, bias=False)\n)"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"test_tokenized_datasets= tokenized_dataset['test']\ntest_tokenized_datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T14:09:29.541908Z","iopub.execute_input":"2025-07-06T14:09:29.542625Z","iopub.status.idle":"2025-07-06T14:09:29.548491Z","shell.execute_reply.started":"2025-07-06T14:09:29.542598Z","shell.execute_reply":"2025-07-06T14:09:29.547905Z"}},"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['content', 'summary', 'input_ids', 'attention_mask', 'labels'],\n    num_rows: 981\n})"},"metadata":{}}],"execution_count":57},{"cell_type":"code","source":"columns_to_remove = ['content', 'summary']\ntest_tokenized_datasets = test_tokenized_datasets.remove_columns(columns_to_remove)\nprint(test_tokenized_datasets)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T14:10:50.365258Z","iopub.execute_input":"2025-07-06T14:10:50.365799Z","iopub.status.idle":"2025-07-06T14:10:50.374085Z","shell.execute_reply.started":"2025-07-06T14:10:50.365778Z","shell.execute_reply":"2025-07-06T14:10:50.373287Z"}},"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['input_ids', 'attention_mask', 'labels'],\n    num_rows: 981\n})\n","output_type":"stream"}],"execution_count":58},{"cell_type":"code","source":"import torch \nimport numpy as np\nfrom evaluate import load\nimport tqdm\nfrom tqdm import tqdm\nmetrics = load(\"rouge\")\n\nmax_target_length = 128\ndataloader = torch.utils.data.DataLoader(test_tokenized_datasets, collate_fn=data_collator, batch_size=32)\n\n\nfor i, batch in enumerate(tqdm(dataloader)):\n  outputs = model.generate(\n      input_ids=batch['input_ids'].to('cuda'),\n      max_length=max_target_length,\n      attention_mask=batch['attention_mask'].to('cuda'),\n  )\n  with tokenizer.as_target_tokenizer():\n    outputs = [tokenizer.decode(out, clean_up_tokenization_spaces=False, skip_special_tokens=True) for out in outputs]\n\n    labels = np.where(batch['labels'] != -100,  batch['labels'], tokenizer.pad_token_id)\n    actuals = [tokenizer.decode(out, clean_up_tokenization_spaces=False, skip_special_tokens=True) for out in labels]\n  predictions.extend(outputs)\n  references.extend(actuals)\n  metrics.add_batch(predictions=outputs, references=actuals)\n\n\nmetrics.compute()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T14:10:53.798070Z","iopub.execute_input":"2025-07-06T14:10:53.798778Z","iopub.status.idle":"2025-07-06T14:13:44.115532Z","shell.execute_reply.started":"2025-07-06T14:10:53.798755Z","shell.execute_reply":"2025-07-06T14:13:44.114819Z"}},"outputs":[{"name":"stderr","text":"  0%|          | 0/31 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3980: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n100%|██████████| 31/31 [02:40<00:00,  5.18s/it]\n","output_type":"stream"},{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"{'rouge1': 0.7619180229245577,\n 'rouge2': 0.5433097205308821,\n 'rougeL': 0.5618782374224933,\n 'rougeLsum': 0.5615724955255126}"},"metadata":{}}],"execution_count":59}]}